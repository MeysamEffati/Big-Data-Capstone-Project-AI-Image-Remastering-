{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5wG-Qe9GRiL",
        "outputId": "6dbd1fe6-a9de-4566-f85e-979205662272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install numpy opencv-python tqdm\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import transforms, ToTensor, ToPILImage\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from tensorboardX import SummaryWriter\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lSRngfllGbla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.prelu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += x\n",
        "        return out\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution block\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "        # Residual blocks\n",
        "        res_blocks = []\n",
        "        for _ in range(n_residual_blocks):\n",
        "            res_blocks.append(ResidualBlock())\n",
        "        self.res_blocks = nn.Sequential(*res_blocks)\n",
        "\n",
        "        # Second conv block after residual blocks\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Final output layer\n",
        "        self.conv3 = nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.prelu(self.conv1(x))\n",
        "        out = self.res_blocks(out1)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = out1 + out\n",
        "        out = self.conv3(out)\n",
        "        return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, stride=1, normalize=True):\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=stride, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 64, stride=2),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 128, stride=2),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 256, stride=2),\n",
        "            *discriminator_block(256, 512),\n",
        "            *discriminator_block(512, 512, stride=2),\n",
        "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "metadata": {
        "id": "3Ec9rqFEGbjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, lr_dir, hr_dir, transform=None):\n",
        "        self.lr_dir = lr_dir\n",
        "        self.hr_dir = hr_dir\n",
        "        self.lr_images = sorted(os.listdir(lr_dir))\n",
        "        self.hr_images = sorted(os.listdir(hr_dir))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_images[index])).convert('RGB')\n",
        "        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_images[index])).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            lr_image = self.transform(lr_image)\n",
        "            hr_image = self.transform(hr_image)\n",
        "\n",
        "        return lr_image, hr_image\n"
      ],
      "metadata": {
        "id": "QKGchUiYGbeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "lr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/low_res'\n",
        "hr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/high_res'\n",
        "batch_size = 16\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = ImageDataset(lr_dir, hr_dir, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Load pre-trained weights for transfer learning\n",
        "pretrained_weight_path = '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x2.pth'\n",
        "generator.load_state_dict(torch.load(pretrained_weight_path, map_location=device), strict=False)\n",
        "\n",
        "# Define loss functions\n",
        "criterion_GAN = nn.BCEWithLogitsLoss().to(device)\n",
        "criterion_content = nn.L1Loss().to(device)\n",
        "\n",
        "# Define optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "log_dir = 'logs'\n",
        "writer = SummaryWriter(log_dir)"
      ],
      "metadata": {
        "id": "b3YlzgGTG3TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning\n",
        "pretrained_weights_path = {\n",
        "    'x2': '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x2.pth',\n",
        "    'x4': '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x4.pth',\n",
        "    'x8': '/content/drive/MyDrive/AI/Term 3/RealESRGAN_weights/RealESRGAN_x8.pth'\n",
        "}\n",
        "\n",
        "# Load pretrained weights into the generator\n",
        "def load_pretrained_weights(generator, pretrained_weights_path):\n",
        "    pretrained_dict = torch.load(pretrained_weights_path, map_location=device)\n",
        "    model_dict = generator.state_dict()\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    generator.load_state_dict(model_dict)\n",
        "\n",
        "# Example: Load x4 pretrained weights\n",
        "load_pretrained_weights(generator, pretrained_weights_path['x4'])\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    for i, (lr, hr) in enumerate(tqdm(train_dataloader)):\n",
        "        lr = lr.to(device)\n",
        "        hr = hr.to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        fake_hr = generator(lr)\n",
        "        real_out = discriminator(hr)\n",
        "        fake_out = discriminator(fake_hr.detach())\n",
        "        real_loss = criterion_GAN(real_out - torch.mean(fake_out), torch.ones_like(real_out))\n",
        "        fake_loss = criterion_GAN(fake_out - torch.mean(real_out), torch.zeros_like(fake_out))\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        fake_out = discriminator(fake_hr)\n",
        "        g_loss_GAN = criterion_GAN(fake_out - torch.mean(real_out.detach()), torch.ones_like(fake_out))\n",
        "        g_loss_content = criterion_content(fake_hr, hr)\n",
        "        g_loss = g_loss_GAN + 1e-2 * g_loss_content\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Logging\n",
        "        writer.add_scalar('Loss/Discriminator', d_loss.item(), epoch * len(train_dataloader) + i)\n",
        "        writer.add_scalar('Loss/Generator', g_loss.item(), epoch * len(train_dataloader) + i)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Delete the previous epoch's models\n",
        "    if epoch > 0:\n",
        "        os.remove(f'/content/drive/MyDrive/AI/Term 3/dataset/generator_epoch_{epoch}.pth')\n",
        "        os.remove(f'/content/drive/MyDrive/AI/Term 3/dataset/discriminator_epoch_{epoch}.pth')\n",
        "\n",
        "    # Save the current epoch's models\n",
        "    torch.save(generator.state_dict(), f'/content/drive/MyDrive/AI/Term 3/dataset/generator_epoch_{epoch+1}.pth')\n",
        "    torch.save(discriminator.state_dict(), f'/content/drive/MyDrive/AI/Term 3/dataset/discriminator_epoch_{epoch+1}.pth')\n",
        "\n",
        "writer.close()\n",
        "\n",
        "# Save the final models\n",
        "torch.save(generator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/generator_final.pth')\n",
        "torch.save(discriminator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/discriminator_final.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMJs_wO6G3Qi",
        "outputId": "28753589-4721-4605-f9cf-4dc0a0908283"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [19:01<00:00, 26.54s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100] Discriminator Loss: 0.0219, Generator Loss: 4.4322\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [15:51<00:00, 22.12s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/100] Discriminator Loss: 0.0640, Generator Loss: 4.3022\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [15:54<00:00, 22.21s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/100] Discriminator Loss: 0.0049, Generator Loss: 5.9592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 43/43 [16:01<00:00, 22.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/100] Discriminator Loss: 0.0017, Generator Loss: 6.8693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 31/43 [11:42<04:31, 22.60s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming the Generator class is defined as before\n",
        "\n",
        "# Path to the saved generator model\n",
        "generator_model_path = '/content/drive/MyDrive/AI/Term 3/dataset/generator_epoch_4.pth'\n",
        "\n",
        "# Load the trained generator model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(torch.load(generator_model_path, map_location=device))\n",
        "generator.eval()\n",
        "\n",
        "# Function to load and preprocess a low-resolution image\n",
        "def load_image(image_path, transform=None):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    if transform:\n",
        "        image = transform(image)\n",
        "    return image\n",
        "\n",
        "# Path to the low-resolution test image\n",
        "test_image_path = '/content/drive/MyDrive/AI/Term 3/dataset/val/low_res/0.png'\n",
        "\n",
        "# Load and preprocess the test image\n",
        "transform = ToTensor()\n",
        "lr_image = load_image(test_image_path, transform).unsqueeze(0).to(device)\n",
        "\n",
        "# Generate the high-resolution image\n",
        "with torch.no_grad():\n",
        "    sr_image = generator(lr_image).squeeze(0).cpu()\n",
        "\n",
        "# Convert the tensor to PIL image\n",
        "to_pil_image = ToPILImage()\n",
        "sr_image = to_pil_image(sr_image)\n",
        "\n",
        "# Save the generated high-resolution image\n",
        "output_image_path = '/content/drive/MyDrive/AI/Term 3/dataset/Test Saved images/generated_sample1.jpg'\n",
        "sr_image.save(output_image_path)\n",
        "\n",
        "# Display the low-resolution and high-resolution images\n",
        "lr_image = lr_image.squeeze(0).cpu()\n",
        "lr_image = to_pil_image(lr_image)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Low-Resolution Image')\n",
        "plt.imshow(lr_image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Generated High-Resolution Image')\n",
        "plt.imshow(sr_image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hsUtwIPlG2-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnreo5zz2cb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}